{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "trained_model_path = Path('artifacts/model_training/model.h5')\n",
    "model = tf.keras.models.load_model(trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertor = tf.lite.TFLiteConverter.from_keras_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\DJ\\AppData\\Local\\Temp\\tmpc5zbaifu\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\DJ\\AppData\\Local\\Temp\\tmpc5zbaifu\\assets\n"
     ]
    }
   ],
   "source": [
    "tflite_model = convertor.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_dir = Path('artifacts/model_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_filepath = tflite_model_dir/'VGG16_model.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59068424"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_filepath.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\DJ\\AppData\\Local\\Temp\\tmpfua8z7dw\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\DJ\\AppData\\Local\\Temp\\tmpfua8z7dw\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14837584"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertor.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "tflite_quant_model = convertor.convert()\n",
    "\n",
    "tflite_quant_model_filepath = tflite_model_dir/'VGG16_quant_model.tflite'\n",
    "tflite_quant_model_filepath.write_bytes(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('artifacts/model_training/VGG16_model.tflite')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading TFLITE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_quant_model_filepath))\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 500, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "input_image = plt.imread('artifacts/data_ingestion/PetImages/Cat/0.jpg')\n",
    "input_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'serving_default_input_1:0',\n",
       "  'index': 0,\n",
       "  'shape': array([  1, 224, 224,   3]),\n",
       "  'shape_signature': array([ -1, 224, 224,   3]),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_input_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_img = tf.image.resize(input_image, (224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_img = tf.expand_dims(resized_img, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 224, 224, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_idx = interpreter.get_input_details()[0]['index']\n",
    "output_idx = interpreter.get_output_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'StatefulPartitionedCall:0',\n",
       "  'index': 50,\n",
       "  'shape': array([1, 2]),\n",
       "  'shape_signature': array([-1,  2]),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_idx, resized_img)\n",
    "interpreter.invoke()\n",
    "pred = interpreter.get_tensor(output_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Got value of type FLOAT64 but expected type FLOAT32 for input 0, name: serving_default_input_1:0 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [37], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m interpreter \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mlite\u001b[39m.\u001b[39mInterpreter(model_path\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(tflite_quant_model_filepath))\n\u001b[0;32m      2\u001b[0m interpreter\u001b[39m.\u001b[39mallocate_tensors()\n\u001b[1;32m----> 3\u001b[0m interpreter\u001b[39m.\u001b[39;49mset_tensor(input_idx, input_image)\n\u001b[0;32m      4\u001b[0m interpreter\u001b[39m.\u001b[39minvoke()\n\u001b[0;32m      5\u001b[0m pred \u001b[39m=\u001b[39m interpreter\u001b[39m.\u001b[39mget_tensor(output_idx)\n",
      "File \u001b[1;32md:\\Full Stack Data Science\\Python Project\\DL\\Current Batch\\Deep_CNN_Classifier\\env\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:697\u001b[0m, in \u001b[0;36mInterpreter.set_tensor\u001b[1;34m(self, tensor_index, value)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_tensor\u001b[39m(\u001b[39mself\u001b[39m, tensor_index, value):\n\u001b[0;32m    682\u001b[0m   \u001b[39m\"\"\"Sets the value of the input tensor.\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \n\u001b[0;32m    684\u001b[0m \u001b[39m  Note this copies data in `value`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[39m    ValueError: If the interpreter could not set the tensor.\u001b[39;00m\n\u001b[0;32m    696\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 697\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpreter\u001b[39m.\u001b[39;49mSetTensor(tensor_index, value)\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set tensor: Got value of type FLOAT64 but expected type FLOAT32 for input 0, name: serving_default_input_1:0 "
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_quant_model_filepath))\n",
    "interpreter.allocate_tensors()\n",
    "interpreter.set_tensor(input_idx, input_image)\n",
    "interpreter.invoke()\n",
    "pred = interpreter.get_tensor(output_idx)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = input_image/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tf\u001b[39m.\u001b[39;49mfloat32(input_image)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DType' object is not callable"
     ]
    }
   ],
   "source": [
    "tf.float32(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae74435513c2e0bf983a5f843fc5bc6ce365fc4d9d78e83d3e0b648a790172b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
